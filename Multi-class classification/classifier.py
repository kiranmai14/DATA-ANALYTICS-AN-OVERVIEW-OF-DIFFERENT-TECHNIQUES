# -*- coding: utf-8 -*-
"""Teamclusters_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S3QA2452t6HfoEEcvyV0MM-M58ma0lRD
"""

'''run it as py teamclusters_classifier.py pathoftraindata pathoftestdata'''
import sys
import pandas as pd
import numpy as np

from matplotlib import pyplot as plt
import seaborn as sns
import random

from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

def preprocessing_train(df,train):
  df = df.drop_duplicates()
  df['Sex'] = df['Sex'].fillna('Missing')
  df['Sex'] = df['Sex'].replace('.', 'Missing', regex=False)
  df.rename(columns = {'Culmen Length (mm)':'culmenlength','Culmen Depth (mm)':'culmendepth','Flipper Length (mm)':'flipperlength',
'Body Mass (g)':'bodymass','Delta 15 N (o/oo)':'delta15N','Delta 13 C (o/oo)':'delta13C','Clutch Completion':'clutchcompletion'}, 
inplace = True)
  train.rename(columns = {'Culmen Length (mm)':'culmenlength','Culmen Depth (mm)':'culmendepth','Flipper Length (mm)':'flipperlength',
'Body Mass (g)':'bodymass','Delta 15 N (o/oo)':'delta15N','Delta 13 C (o/oo)':'delta13C','Clutch Completion':'clutchcompletion'}, 
inplace = True)
  df['Island'] = df['Island'].fillna('Missing')
  df['clutchcompletion'] = df['clutchcompletion'].fillna('Missing')
  frames = []
  for i in list(set(train['Species'])):
      df_species = train[train['Species']== i]
      #df_spec = df[df['Species']==i]
      df_species['delta13C'].fillna(df_species['delta13C'].mean(),inplace = True)
      df_species['culmenlength'].fillna(df_species['culmenlength'].mean(),inplace = True)
      df_species['culmendepth'].fillna(df_species['culmendepth'].mean(),inplace = True)
      df_species['flipperlength'].fillna(df_species['flipperlength'].mean(),inplace = True)
      df_species['bodymass'].fillna(df_species['bodymass'].mean(),inplace = True)
      df_species['delta15N'].fillna(df_species['delta15N'].mean(),inplace = True)
      frames.append(df_species)
      final_df = pd.concat(frames)
  df = final_df

  return df

def preprocessing_test(df,train):
  df = df.drop_duplicates()
  df['Sex'] = df['Sex'].fillna('Missing')
  df['Sex'] = df['Sex'].replace('.', 'Missing', regex=False)
  df.rename(columns = {'Culmen Length (mm)':'culmenlength','Culmen Depth (mm)':'culmendepth','Flipper Length (mm)':'flipperlength',
'Body Mass (g)':'bodymass','Delta 15 N (o/oo)':'delta15N','Delta 13 C (o/oo)':'delta13C','Clutch Completion':'clutchcompletion'}, 
inplace = True)
  train.rename(columns = {'Culmen Length (mm)':'culmenlength','Culmen Depth (mm)':'culmendepth','Flipper Length (mm)':'flipperlength',
'Body Mass (g)':'bodymass','Delta 15 N (o/oo)':'delta15N','Delta 13 C (o/oo)':'delta13C','Clutch Completion':'clutchcompletion'}, 
inplace = True)
  df['Island'] = df['Island'].fillna('Missing')
  df['clutchcompletion'] = df['clutchcompletion'].fillna('Missing')
  frames = []
  df['delta13C'].fillna(train['delta13C'].mean(),inplace = True)
  df['culmenlength'].fillna(train['culmenlength'].mean(),inplace = True)
  df['culmendepth'].fillna(train['culmendepth'].mean(),inplace = True)
  df['flipperlength'].fillna(train['flipperlength'].mean(),inplace = True)
  df['bodymass'].fillna(train['bodymass'].mean(),inplace = True)
  df['delta15N'].fillna(train['delta15N'].mean(),inplace = True)
  frames.append(df)
  final_df = pd.concat(frames)
  df = final_df

  return df


def data_augmentation(df):
  columns_list = list(df.columns)
  penguin_list = list(df.to_numpy())
  i=0
  while i<100:
    ind = random.randint(0,len(penguin_list)-1)
    ele = penguin_list[ind].copy()
    # print(ele)
    val = random.choice(['Dream', 'Biscoe', 'Torgersen'])
    ele[0] = val
    val = random.choice(['Yes', 'No'])
    ele[1] = val
    val = round(random.uniform(ele[2]-10,ele[2]+10),1)
    ele[2] = val
    val = round(random.uniform(ele[3]-10,ele[3]+10),1)
    ele[3] = val
    val = round(random.uniform(ele[4]-30,ele[4]+30),1)
    ele[4] = val
    val = round(random.uniform(ele[5]-500,ele[5]+500),1)
    ele[5] = val
    val = random.choice(['MALE', 'FEMALE', 'Missing'])
    ele[6] = val
    val = round(random.uniform(ele[7]-5,ele[7]+5),1)
    ele[7] = val
    val = round(random.uniform(ele[8]-10,ele[8]+10),1)
    ele[8] = val
    i=i+1
    penguin_list.append(ele)
  df = pd.DataFrame(penguin_list,columns = columns_list)
  return df

def prepare_data(df):
  for column in df.select_dtypes(exclude=['object']):
    df[column] = (df[column] -
                            df[column].mean()) / df[column].std()
  labels = []
  for column in df.select_dtypes(include=['object']):
     label_encoder = preprocessing.LabelEncoder()
     df[column]= label_encoder.fit_transform(df[column])
     if column =="Species":
       labels = list(label_encoder.classes_)

  return df,labels

def make_prediction(x,labels,classifier_0_1,classifier_1_2,classifier_2_0):
  y_pred_1 = classifier_0_1.predict(x)
  y_pred_2 = classifier_1_2.predict(x)
  y_pred_3 = classifier_2_0.predict(x)

  y_pred = []
  for i in range(len(y_pred_1)):
    list1 = [0,0,0]
    list1[y_pred_1[i]]+=1
    list1[y_pred_2[i]]+=1
    list1[y_pred_3[i]]+=1
    y_pred.append(labels[list1.index(max(list1))])
  
  return y_pred

def make_classifier_knn(x1,x2,y1,y2,param_grid):
  x0 = np.append(x1,x2,axis=0)
  y0 = np.append(y1,y2,axis=0)
  
  neigh = KNeighborsClassifier()
  knn_gscv = GridSearchCV(neigh, param_grid, cv=5)
  knn_gscv.fit(x0,y0)
  return knn_gscv

def make_classifier_dtc(x1,x2,y1,y2,parameters):
  x0 = np.append(x1,x2,axis=0)
  y0 = np.append(y1,y2,axis=0)
  clf = GridSearchCV(DecisionTreeClassifier(), parameters, n_jobs=4)
  clf.fit(X=x0, y=y0)
  return clf

def make_classifier_rf(x1,x2,y1,y2,parameters):
  x0 = np.append(x1,x2,axis=0)
  y0 = np.append(y1,y2,axis=0)
  clf = GridSearchCV(RandomForestClassifier(), parameters, n_jobs=4)
  clf.fit(X=x0, y=y0)
  return clf

#loading data
train_path =  sys.argv[0]
test_path =   sys.argv[1]
train_df = pd.read_csv(train_path)
test_df = pd.read_csv(test_path)

train_df = preprocessing_train(train_df,train_df)
test_df = preprocessing_test(test_df,train_df)

train_df = data_augmentation(train_df)

train_df,labels = prepare_data(train_df)
test_df,_ = prepare_data(test_df)

x = train_df.drop(columns=['Species']) 
y = train_df['Species']

x_train = x.to_numpy()
y_train = y.to_numpy()

x_train_0 = []
x_train_1 = []
x_train_2 = []
y_train_0 = []
y_train_1 = []
y_train_2 = []

for i in range(len(y_train)):
  if y_train[i] == 0:
    x_train_0.append(x_train[i])
    y_train_0.append(0)
  elif y_train[i] ==1:
    x_train_1.append(x_train[i])
    y_train_1.append(1)
  else:
    x_train_2.append(x_train[i])
    y_train_2.append(2)

x_train_0 = np.array(x_train_0)
x_train_1 = np.array(x_train_1)
x_train_2 = np.array(x_train_2)
y_train_0 = np.array(y_train_0)
y_train_1 = np.array(y_train_1)
y_train_2 = np.array(y_train_2)

param_grid = {'n_neighbors': np.arange(1, 25)}
classifier_0_1 = make_classifier_knn(x_train_0,x_train_1,y_train_0,y_train_1,param_grid)
classifier_1_2 = make_classifier_knn(x_train_1,x_train_2,y_train_1,y_train_2,param_grid)
classifier_2_0 = make_classifier_knn(x_train_2,x_train_0,y_train_2,y_train_0,param_grid) 

y_pred = make_prediction(test_df.to_numpy(),labels,classifier_0_1,classifier_1_2,classifier_2_0)

dic={}
dic["predicted_value"] = y_pred

ans_df = pd.DataFrame(dic)
ans_df.to_csv("predicted_knn.csv")

parameters = {'max_depth':range(3,20)}
classifier_0_1 = make_classifier_dtc(x_train_0,x_train_1,y_train_0,y_train_1,parameters)
classifier_1_2 = make_classifier_dtc(x_train_1,x_train_2,y_train_1,y_train_2,parameters)
classifier_2_0 = make_classifier_dtc(x_train_2,x_train_0,y_train_2,y_train_0,parameters) 

y_pred = make_prediction(test_df.to_numpy(),labels,classifier_0_1,classifier_1_2,classifier_2_0)

dic={}
dic["predicted_value"] = y_pred

ans_df = pd.DataFrame(dic)
ans_df.to_csv("predicted_dtc.csv")

classifier_0_1 = make_classifier_rf(x_train_0,x_train_1,y_train_0,y_train_1,parameters)
classifier_1_2 = make_classifier_rf(x_train_1,x_train_2,y_train_1,y_train_2,parameters)
classifier_2_0 = make_classifier_rf(x_train_2,x_train_0,y_train_2,y_train_0,parameters) 

y_pred = make_prediction(test_df.to_numpy(),labels,classifier_0_1,classifier_1_2,classifier_2_0)

dic={}
dic["predicted_value"] = y_pred

ans_df = pd.DataFrame(dic)
ans_df.to_csv("predicted_rf.csv")

