# -*- coding: utf-8 -*-
"""Teamclusters_recommender.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SJJjjY5G1Y046K9vxc-lfkrR0IfYmn73
"""

#connecting to google drive
#from google.colab import drive
#drive.mount('/content/drive')

#required packages...
import pandas as pd
import numpy as np
import random 
import itertools
import sys
import matplotlib.pyplot as plt

movies_df = pd.read_csv(sys.argv[0])

movies_arr = movies_df.to_numpy()
movies_index = {}
for i in movies_arr:
  movies_index[i[0]] = i[1]

#loading the data that the rules were generated....
f = open(sys.argv[1],'rb')
d = np.load(f,allow_pickle = True)
f.close()
train_set,test_set,set_train_set = d[0],d[1],d[2]

#loading the rules file that we generated from the ruleminer
f = open(sys.argv[2],'rb')
d = np.load(f,allow_pickle = True)
f.close()
support,confidence,rules_sup,rules_conf = d[0],d[1],d[2],d[3]

#a function to sort the rules based on support and confidence
def sort_rules(data,rules):

  combined = []
  for i in range(len(data)):

    l=[]
    l.append(rules[i][0])
    l.append(rules[i][1])
    l.append(data[i])
    combined.append(l)

  combined.sort(key=lambda x: x[-1],reverse=True)
  return combined

# a function to get the common rules from two set of rules.
def get_common_rules(rules_sup,rules_conf):

  new_rules = []

  for sup in rules_sup:
    for conf in rules_conf:
      if(sup[:-1] == conf[:-1]):
        new_rules.append(conf)
        break
  
  new_rules.sort(key=lambda x: x[-1],reverse=True)
  return new_rules

#sorting the rules based on support
sorted_sup_rules = sort_rules(support,rules_sup)

#sorting the rules based on confidence
sorted_conf_rules = sort_rules(confidence,rules_conf)

#taking top 100 support and top 100 confidence rules
top_100_sup_rules = sorted_sup_rules[:100]
top_100_conf_rules = sorted_conf_rules[:100]

#common rules 
recommendation_rules = get_common_rules(top_100_sup_rules,top_100_conf_rules)

len(recommendation_rules)

#writing the rules into the text files..
f = open('Teamclusters_RulesMaxSupport.txt','w')
for rule in top_100_sup_rules:
  f.write(str(movies_index[rule[0]]))
  f.write("->")
  for y in rule[1]:
    f.write(str(movies_index[y]))
    f.write(',')
  f.write('\n')
f.close()

f = open('Teamclusters_RulesMaxConf.txt','w')
for rule in top_100_conf_rules:
  f.write(str(movies_index[rule[0]]))
  f.write("->")
  for y in rule[1]:
    f.write(str(movies_index[y]))
    f.write(',')
  f.write('\n')
f.close()

f = open('Teamclusters_AssocRules.txt','w')
for rule in recommendation_rules:
  f.write(str(movies_index[rule[0]]))
  f.write("->")
  for y in rule[1]:
    f.write(str(movies_index[y]))
    f.write(',')
  f.write('\n')
f.close()

def calculate_precision_recall(movies_train_list,movies_test_list,rules):

  # take each movie 
  # get first rule for that movie
  # create recommendation set after traversing all movies for that user
  # intersect that R with test set -> hit set
  # ratio of hit set/test = recall
  # ratio of hit set/R = precision

  
  recommendation = {}
  precison = {}
  recall = {}
  

  for rule_no in range(1,11):

    for movie in movies_train_list:

      p = 1
      for rule in rules:

        if(rule[0] == movie):
          if(rule_no not in recommendation):
            recommendation[rule_no] = []

          for mv in rule[1]:
            recommendation[rule_no].append(mv)
          p+=1
          if(p > rule_no):
            break


  for rule_no,mvs in recommendation.items():
    recommendation[rule_no] = set(mvs)
  

  hit_set = {}
  recall = {}
  precision = {}

  movies_test_set = set(movies_test_list)
  

  for rule_no, mvs in recommendation.items():

    l = movies_test_set.intersection(mvs)
    hit_set[rule_no] = list(l)
    recall[rule_no] = len(hit_set)/len(movies_test_set)
    precision[rule_no] = len(hit_set)/len(mvs)
  
  return recall,precision

def get_precision_recall(train_set,test_set,rules):

  precision = {}
  recall = {}
  k=0

  for userid in train_set.keys():
    k+=1
    r,p = calculate_precision_recall(train_set[userid],test_set[userid],rules)


    for key,val in r.items():

      if(key not in recall):
        recall[key] = []

      recall[key].append(val)
    
    for key,val in p.items():

      if(key not in precision):
        precision[key] = []
      
      precision[key].append(val)
  return recall,precision

#driver code for calculating recall and precision of consideration of 1 to 10 rules.
recall,precision = get_precision_recall(train_set,test_set,sorted_conf_rules)

#a function to get the average of the recall and precision that were calculated
def get_avg_precision_recall(recall,precision):

  avg_precision = {}
  avg_recall = {}

  for key,val in recall.items():
    avg_recall[key] = sum(val)/len(val)
  
  for key,val in precision.items():
    avg_precision[key] = sum(val)/len(val)
  
  return avg_recall, avg_precision

avg_recall, avg_precision = get_avg_precision_recall(recall,precision)

# a function to plot the data
def plot_graph(data,name_x,name_y,title):


  x = list(data.keys())
  y = []

  for k,v in data.items():
    y.append(v)

  plt.plot(x, y)

  plt.xlabel(name_x)
  plt.ylabel(name_y)
  plt.title(title)
  plt.show()

plot_graph(avg_recall,'count of rules','recall','recall vs count of rules')

plot_graph(avg_precision,'count of rules','precision','precision vs count of rules')

"""### precision ,recall sample users"""

def get_precision_recall_users(train_set,test_set,rules):
  
  precision = {}
  recall = {}

  user_recommendations = {}
  rec_size = 30

  for userid,mvs in train_set.items():

    if(userid not in user_recommendations):
      user_recommendations[userid] = []
    
    k = 0
    for rule in rules:

      if(rule[0] in mvs):
        for m in rule[1]:
          user_recommendations[userid].append(m)

        k+=len(set(user_recommendations[userid]))
        if( k >= rec_size):
          break
  
  for userid,recs in user_recommendations.items():

    hitset = set(user_recommendations[userid]).intersection(test_set[userid])
    recall[userid] = len(hitset)/len(test_set[userid])
    if len(user_recommendations[userid])!=0:
      precision[userid] = len(hitset)/len(user_recommendations[userid])
    else:
      precision[userid] = 0
  return recall,precision

new_train_dict = {}
new_test_dict = {}

cnt = 0
for key,val in train_set.items():
  new_train_dict[key] = val
  cnt+=1
  if(cnt>=10):
    break

for key in new_train_dict.keys():
  new_test_dict[key] = test_set[key]

recall_users,precision_users = get_precision_recall_users(new_train_dict,new_test_dict,sorted_conf_rules)

plot_graph(recall_users,'userid','recall','recall of 10 users')

plot_graph(precision_users,'userid','precision','precision of 10 users')
